{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "path_to_add = os.path.join(parent_dir, \"src\")\n",
    "sys.path.insert(0, path_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "## Free text comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import janitor\n",
    "\n",
    "# URL of the endpoint\n",
    "url = \"https://data.austintexas.gov/resource/jeyv-db9u.json\"\n",
    "\n",
    "# Fetch the data from the API\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.DataFrame(response.json()).clean_names()\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions data (likert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_likert = \"https://data.austintexas.gov/resource/s2py-ceb7.json\"\n",
    "\n",
    "response = requests.get(url_likert)\n",
    "if response.status_code == 200:\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    dfq = pd.DataFrame(response.json())\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'method', 'the_city_of_austin_as_a_place',\n",
       "       'the_city_of_austin_as_a_place_1', 'the_city_of_austin_as_a_place_2',\n",
       "       'the_city_of_austin_as_a_place_3', 'overall_quality_of_life_in',\n",
       "       'how_well_the_city_of_austin', 'access_to_affordable_quality',\n",
       "       ...\n",
       "       'date_as_of_date', 'which_of_the_following_best_7',\n",
       "       'which_of_the_following_best_8', 'which_of_the_following_best_6',\n",
       "       'which_of_the_following_best_3', 'which_of_the_following_best_2',\n",
       "       'safety_in_city_parks_and', 'overall_quality_of_planning_1',\n",
       "       'bicycle_accessibility_the', 'overall_maintenance_of_city_1'],\n",
       "      dtype='object', length=159)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dissatisfied',\n",
       " \"Don't Know\",\n",
       " 'Neutral',\n",
       " 'Satisfied',\n",
       " 'Very Dissatisfied',\n",
       " 'Very Satisfied'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "set(np.hstack(dfq[['the_city_of_austin_as_a_place_1', 'the_city_of_austin_as_a_place_2',\n",
    "       'the_city_of_austin_as_a_place_3', 'overall_quality_of_life_in',]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq.to_excel('austin_likert.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\i5\\Documents\\Python Scripts\\pandas-survey-toolkit\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\i5\\Documents\\Python Scripts\\pandas-survey-toolkit\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from pandas_survey_toolkit import analytics, nlp, vis\n",
    "from pandas_survey_toolkit.vis import create_keyword_graph, visualize_keyword_graph,visualize_keyword_graph_force, create_keyword_sentiment_df_simple, create_sentiment_color_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\i5\\Documents\\Python Scripts\\pandas-survey-toolkit\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "df2 = df.cluster_comments(\"response\").extract_keywords(\"response\", top_n=4, ngram_range=(1,1), min_df=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel(\"austin_comments.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfx = df2[['response', 'cluster', 'keywords']]\n",
    "dfx = dfx.reset_index()\n",
    "dfx[\"comment_id\"] = dfx[\"index\"].astype(str).apply(lambda x: \"comment_\" + x)\n",
    "dfx[\"cluster_id\"] = dfx[\"cluster\"].astype(int).astype(str).apply(lambda x: \"category_\" + x)\n",
    "dfx = dfx.query(\"cluster >= 0 & cluster < 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "import networkx as nx\n",
    "%autoreload 2\n",
    "from pandas_survey_toolkit.vis import plot_pyvis_network, create_keyword_graph, create_comment_keyword_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network plot saved to network.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G = nx.DiGraph()\n",
    "#add cluster_id nodes\n",
    "\n",
    "for category in dfx[\"cluster\"]:\n",
    "    category = int(category)\n",
    "    if category == -1:\n",
    "        continue\n",
    "    G.add_node(\"category_\" + str(category), group=\"category\", index=category)\n",
    "#G.add_nodes_from(dfx[\"cluster_id\"].astype(str).unique(), group=\"category\")\n",
    " # Create a list of tuples (node, attr_dict) for each row in the DataFrame\n",
    "nodes_with_attrs = dfx.apply(lambda row: (row['comment_id'], {'text': row['response'], 'group' : 'comment'}), axis=1).tolist()\n",
    "    \n",
    " # Add nodes to the graph with their attributes\n",
    "G.add_nodes_from(nodes_with_attrs)\n",
    "\n",
    "G.add_edges_from(dfx[[\"cluster_id\", \"comment_id\"]].values)\n",
    "\n",
    "\n",
    "#now add keyword graph\n",
    "G_kw = create_keyword_graph(dfx, keyword_column=\"keywords\")\n",
    "#now add link from comment to keywords\n",
    "edge_list_comment_keywords = create_comment_keyword_edges(dfx)\n",
    "\n",
    "G2 = nx.compose(G, G_kw)\n",
    "\n",
    "G2.add_edges_from(edge_list_comment_keywords)\n",
    "plot_pyvis_network(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "\n",
    "def export_graph(G):\n",
    "    nodes = []\n",
    "    links = []\n",
    "    \n",
    "    for node, data in G.nodes(data=True):\n",
    "        node_data = {\n",
    "            \"id\": node,\n",
    "            \"group\": data[\"group\"],\n",
    "            \"size\": data.get(\"node_count\", 1)  # Default size to 1 if not specified\n",
    "        }\n",
    "        if data[\"group\"] == \"category\":\n",
    "            node_data[\"index\"] = data[\"index\"]  # For positioning around the circle\n",
    "        nodes.append(node_data)\n",
    "    \n",
    "    for source, target, data in G.edges(data=True):\n",
    "        links.append({\n",
    "            \"source\": source,\n",
    "            \"target\": target,\n",
    "            \"value\": data.get(\"edge_count\", 1)  # Default to 1 if not specified\n",
    "        })\n",
    "    \n",
    "    return json.dumps({\"nodes\": nodes, \"links\": links}, indent=2)\n",
    "\n",
    "# Usage\n",
    "graph_json = export_graph(G2)  # G is your NetworkX graph\n",
    "with open(\"graph_data.json\", \"w\") as f:\n",
    "    f.write(graph_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to keyword_sentiment_graph.html\n"
     ]
    }
   ],
   "source": [
    "sentiment_df = create_keyword_sentiment_df_simple(df2)\n",
    "sentiment_df = sentiment_df.query(\"word != 'not'\")\n",
    "color_mapping = create_sentiment_color_mapping(sentiment_df)\n",
    "\n",
    "G = create_keyword_graph(df2, 'keywords', node_color_mapping=color_mapping)\n",
    "G.remove_node(\"not\")\n",
    "visualize_keyword_graph_force(G, output_file='keyword_sentiment_graph.html', colormap='RdBu', min_edge_count=2, min_node_count=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
